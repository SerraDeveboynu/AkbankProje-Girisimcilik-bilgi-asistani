import os
import streamlit as st
import google.generativeai as genai
from sentence_transformers import SentenceTransformer
import numpy as np
import chromadb
from chromadb.config import Settings
from pathlib import Path

# ========== SAYFA ==========
st.set_page_config(page_title="GiriÅŸimcilik Bilgi AsistanÄ±", layout="wide")
st.title("ðŸ’¬ GiriÅŸimcilik Bilgi AsistanÄ±")
st.caption("TÃœBÄ°TAK, KOSGEB ve TEKNOFEST metinlerinden RAG ile yanÄ±t Ã¼retir. (Gemini 2.5-flash)")

# ========== API ANAHTARI ==========
API_KEY = st.secrets.get("GENAI_API_KEY", None) or os.getenv("GENAI_API_KEY")
if not API_KEY:
    st.error(" API anahtarÄ± bulunamadÄ±. LÃ¼tfen Streamlit Secrets veya ortam deÄŸiÅŸkenine 'GENAI_API_KEY' ekleyin.")
    st.stop()

genai.configure(api_key=API_KEY)
gmodel = genai.GenerativeModel("gemini-2.5-flash")

# ========== YOLLAR ==========
DATA_DIR = Path("./data")
DB_DIR = Path("./girisim_db")
DB_DIR.mkdir(exist_ok=True)

# ========== EMBEDDING ==========
@st.cache_resource
def load_embedder():
    return SentenceTransformer("intfloat/multilingual-e5-small")

embedder = load_embedder()

def embed_texts(texts):
    vecs = embedder.encode(texts, normalize_embeddings=True)
    return np.asarray(vecs, dtype=np.float32)

def split_text(text, chunk_size=800, overlap=120):
    chunks, start, n = [], 0, len(text)
    while start < n:
        end = min(start + chunk_size, n)
        chunks.append(text[start:end])
        if end == n:
            break
        start = end - overlap
    return chunks

# ========== CHROMADB ==========
client = chromadb.PersistentClient(path=str(DB_DIR), settings=Settings(allow_reset=True))
collection = client.get_or_create_collection(name="girisim", metadata={"hnsw:space": "cosine"})

def rebuild_index_from_data_dir():
    if not DATA_DIR.exists():
        raise RuntimeError("data/ klasÃ¶rÃ¼ bulunamadÄ±.")
    texts, metadatas, ids = [], [], []
    for f in DATA_DIR.glob("*.txt"):
        raw = f.read_text(encoding="utf-8", errors="ignore")
        parts = split_text(raw, 800, 120)
        for i, p in enumerate(parts):
            texts.append(p)
            metadatas.append({"source": f.name, "part": i+1})
            ids.append(f"{f.stem}-{i+1:05d}")
    if not texts:
        raise RuntimeError("data/ klasÃ¶rÃ¼nde .txt dosyasÄ± yok.")
global collection
try:
    client.delete_collection(name="girisim")
except Exception:
    pass

collection = client.get_or_create_collection(
    name="girisim",
    metadata={"hnsw:space": "cosine"}
)

vecs = embed_texts(texts)
collection.add(ids=ids, documents=texts, embeddings=vecs.tolist(), metadatas=metadatas)
return len(texts)

def retrieve(query, k=4):
    qvec = embed_texts([query])[0].tolist()
    res = collection.query(query_embeddings=[qvec], n_results=k, include=["documents", "metadatas"])
    docs = res["documents"][0]
    metas = res["metadatas"][0]
    return list(zip(docs, metas))

SYSTEM_PROMPT = (
    "Sen TÃ¼rkÃ§e konuÅŸan bir giriÅŸimcilik danÄ±ÅŸmanÄ± asistansÄ±n. "
    "CevaplarÄ±nÄ± verilen iÃ§erik parÃ§alarÄ±na dayandÄ±r; emin deÄŸilsen 'bilmiyorum' de. "
    "YanÄ±tlarÄ±nda [Kaynak] numaralarÄ±nÄ± parantez iÃ§inde belirt."
)

# ========== ARAYÃœZ ==========
st.markdown("### ðŸ“‚ Belgeler")
colA, colB, colC = st.columns([1, 1, 1])

with colA:
    if st.button("./data klasÃ¶rÃ¼nden indeksi oluÅŸtur (veya yenile)"):
        try:
            n = rebuild_index_from_data_dir()
            st.success(f" Ä°ndeks baÅŸarÄ±yla oluÅŸturuldu. Toplam parÃ§a: {n}")
        except Exception as e:
            st.error(f" Hata: {e}")

with colB:
    k = st.slider("ðŸ” Aranacak parÃ§a sayÄ±sÄ± (k)", 1, 8, 4, 1)

st.markdown("---")
st.markdown("### ðŸ’¬ Soru Sor")

if "chat" not in st.session_state:
    st.session_state.chat = []

for m in st.session_state.chat:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

if prompt := st.chat_input("Ã–rn: 'KOSGEB genÃ§ giriÅŸimcilere hangi destekleri saÄŸlar?'"):
    st.session_state.chat.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("YanÄ±t hazÄ±rlanÄ±yor..."):
            try:
                retrieved = retrieve(prompt, k=k)
                if not retrieved:
                    raise RuntimeError("Ä°ndeks boÅŸ. Ã–nce 'Ä°ndeksi oluÅŸtur' butonuna basÄ±n.")
                ctx = "\n\n".join([f"[Kaynak {i+1}] {doc}" for i, (doc, meta) in enumerate(retrieved)])
                full_prompt = (
                    f"{SYSTEM_PROMPT}\n\n"
                    f"KullanÄ±cÄ± sorusu: {prompt}\n\n"
                    f"Ä°lgili iÃ§erik parÃ§alarÄ±:\n{ctx}\n\n"
                    "YanÄ±tÄ±nda kullandÄ±ÄŸÄ±n [Kaynak] numaralarÄ±nÄ± parantez iÃ§inde belirt."
                )
                resp = gmodel.generate_content(full_prompt)
                answer = resp.text if hasattr(resp, "text") else str(resp)
                st.markdown(answer)

                with st.expander("ðŸ“Ž KullanÄ±lan kaynak parÃ§alar"):
                    for i, (doc, meta) in enumerate(retrieved, 1):
                        src = meta.get("source", "dosya")
                        part = meta.get("part", "?")
                        snippet = (doc[:300] + "â€¦") if len(doc) > 300 else doc
                        st.markdown(f"**Kaynak {i}** â€” `{src}` (parÃ§a {part})\n\n> {snippet}\n\n---")

            except Exception as e:
                answer = f" Hata: {e}"
                st.error(answer)

    st.session_state.chat.append({"role": "assistant", "content": answer})


